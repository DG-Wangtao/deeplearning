{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6361775,"sourceType":"datasetVersion","datasetId":3664633}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 安装依赖","metadata":{}},{"cell_type":"markdown","source":"- https://github.com/milesial/Pytorch-UNet/tree/master\n- https://github.com/njcronin/DL_Track\n- https://github.com/njcronin/DL_Track/blob/master/Labelling_Instructions.pdf","metadata":{}},{"cell_type":"code","source":"!pip install scipy scikit-image torch torchvision pathlib wandb segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:39:49.260357Z","iopub.execute_input":"2023-12-20T16:39:49.260831Z","iopub.status.idle":"2023-12-20T16:40:00.737750Z","shell.execute_reply.started":"2023-12-20T16:39:49.260795Z","shell.execute_reply":"2023-12-20T16:40:00.736465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 引用依赖包","metadata":{}},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.740417Z","iopub.execute_input":"2023-12-20T16:40:00.740842Z","iopub.status.idle":"2023-12-20T16:40:00.751130Z","shell.execute_reply.started":"2023-12-20T16:40:00.740797Z","shell.execute_reply":"2023-12-20T16:40:00.750088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.nn.functional import relu, pad\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom PIL import Image\nfrom typing import Tuple\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom tqdm import tqdm\nimport wandb\nimport logging","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.752565Z","iopub.execute_input":"2023-12-20T16:40:00.752944Z","iopub.status.idle":"2023-12-20T16:40:00.767673Z","shell.execute_reply.started":"2023-12-20T16:40:00.752896Z","shell.execute_reply":"2023-12-20T16:40:00.766424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## U-Net 网络","metadata":{}},{"cell_type":"code","source":"class GroupNorm2d(nn.Module):\n\n    def __init__(self, n_groups: int = 16, n_channels: int = 16, eps: float = 1e-10):\n        super(GroupNorm2d, self).__init__()  \n        print(\"n_channels: \", n_channels, \"n_groups: \", n_groups)\n        assert n_channels % n_groups == 0 \n        self.n_groups = n_groups  \n        self.gamma = nn.Parameter(torch.randn(n_channels, 1, 1))  # learnable gamma\n        self.beta = nn.Parameter(torch.zeros(n_channels, 1, 1))  # learnable beta\n        self.eps = eps \n\n    def forward(self, x):\n        N, C, H, W = x.size()\n        x = x.reshape(N, self.n_groups, -1) \n        mean = x.mean(dim=2, keepdim=True)  \n        std = x.std(dim=2, keepdim=True)\n        x = (x - mean) / (std + self.eps) \n        x = x.reshape(N, C, H, W)  \n        return x * self.gamma + self.beta  \n\n\n# Spatial and Reconstruct Unit\nclass SRU(nn.Module):\n\n    def __init__(\n            self,\n            n_channels: int,  # in_channels\n            n_groups: int = 16,  # 16\n            gate_treshold: float = 0.5,  # 0.5,\n            torch_gn:bool = True\n    ):\n        super().__init__()  \n\n        # initialize GroupNorm2d\n        self.gn = nn.GroupNorm( num_channels = n_channels, num_groups = n_groups ) if torch_gn else GroupNorm2d(n_channels = n_channels, n_groups = n_groups)\n        # self.gn = GroupNorm2d(n_groups=n_groups, n_channels=n_channels)\n        self.gate_treshold = gate_treshold  \n        self.sigomid = nn.Sigmoid()  \n\n    def forward(self, x):\n        gn_x = self.gn(x) \n        w_gamma = self.gn.gamma / sum(self.gn.gamma)  # cal gamma weight\n        reweights = self.sigomid(gn_x * w_gamma)  # importance\n\n        info_mask = reweights >= self.gate_treshold\n        noninfo_mask = reweights < self.gate_treshold\n        x_1 = info_mask * x  \n        x_2 = noninfo_mask * x  \n        x = self.reconstruct(x_1, x_2) \n        return x\n\n    def reconstruct(self, x_1, x_2):\n        x_11, x_12 = torch.split(x_1, x_1.size(1) // 2, dim=1)\n        x_21, x_22 = torch.split(x_2, x_2.size(1) // 2, dim=1)\n        return torch.cat([x_11 + x_22, x_12 + x_21], dim=1)\n\n\n# Channel Reduction Unit\nclass CRU(nn.Module):\n\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3, alpha: float = 1 / 2, squeeze_radio: int = 2, groups: int = 2):\n        super().__init__()\n\n        self.up_channel = up_channel = int(alpha * in_channels)\n        self.low_channel = low_channel = in_channels - up_channel\n        self.squeeze1 = nn.Conv2d(up_channel, up_channel // squeeze_radio, kernel_size=1, bias=False)\n        self.squeeze2 = nn.Conv2d(low_channel, low_channel // squeeze_radio, kernel_size=1, bias=False)\n\n        in_ch = up_channel // squeeze_radio\n        out_ch = out_channels\n        print(\"out_channels:\", out_channels, \"squeeze_radio: \", squeeze_radio, \"up_channel: \",up_channel,\"in_ch (out_channels // squeeze_radio): \", in_ch, \"out_ch(out_channels):\", out_ch)\n        \n        \n        if in_ch >= 16:\n            groups = 16\n    \n        self.GWC = nn.Conv2d(in_ch, out_channels, kernel_size=kernel_size, stride=1, padding=kernel_size // 2, groups=groups) \n        self.PWC1 = nn.Conv2d(in_ch, out_channels, kernel_size=1, bias=False)\n\n        print(\"in_channels: \", in_channels, \"out_channels: \", out_channels)\n        print(\"up_channel: \", self.up_channel, \"low_channel: \", self.low_channel)\n        in_ch = low_channel // squeeze_radio\n        out_ch = out_channels - low_channel // squeeze_radio\n        print(\"out_channels:\", out_channels, \"squeeze_radio: \", squeeze_radio, \"low_channel: \",low_channel,\"in_ch (low_channel // squeeze_radio): \", in_ch, \"out_ch(out_channels - low_channel // squeeze_radio):\", out_ch)\n        self.PWC2 = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False) \n        #print(\"self.PWC2.weight.shape: \",self.PWC2.weight.shape)\n        self.pool = nn.AdaptiveAvgPool2d(1)  \n        \n    def forward(self, x):\n\n        up, low = torch.split(x, [self.up_channel, self.low_channel], dim=1)\n        up, low = self.squeeze1(up), self.squeeze2(low)\n\n        y1 = self.GWC(up) + self.PWC1(up)\n        \n        #print(\"low: \",low.shape)\n        pwc2 = self.PWC2(low)\n        #print(\"pwc2\", pwc2.shape)\n        y2 = torch.cat([pwc2, low], dim=1)\n\n        s1 = self.pool(y1)\n        s2 = self.pool(y2)\n        s = torch.cat([s1, s2], dim=1)\n        beta = F.softmax(s, dim=1)\n        beta1, beta2 = torch.split(beta, beta.size(1) // 2, dim=1)\n        y = beta1 * y1 + beta2 * y2\n        return y\n\n\n# Squeeze and Channel Reduction Convolution\nclass ScConv(nn.Module):\n\n    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3, stride: int = 1, padding: int = 1, n_groups: int = 2, gate_treshold: float = 0.5, alpha: float = 1 / 2, squeeze_radio: int = 2, groups: int = 2):\n        super().__init__()\n\n        self.SRU = SRU(in_channels, n_groups=n_groups, gate_treshold=gate_treshold, torch_gn=False) \n        self.CRU = CRU(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, alpha=alpha, squeeze_radio=squeeze_radio, groups=groups)\n\n    def forward(self, x):\n        x = self.SRU(x)  \n        x = self.CRU(x) \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.770899Z","iopub.execute_input":"2023-12-20T16:40:00.771452Z","iopub.status.idle":"2023-12-20T16:40:00.803276Z","shell.execute_reply.started":"2023-12-20T16:40:00.771407Z","shell.execute_reply":"2023-12-20T16:40:00.802159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3):\n        super(DoubleConv,self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n    \nclass ScDoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3):\n        super(DoubleConv,self).__init__()\n        self.double_conv = nn.Sequential(\n            ScConv(in_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            ScConv(out_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3, dropout = 0.1):\n        super(Down, self).__init__()\n        self.double_conv = DoubleConv(in_channels, out_channels, kernel_size)\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p=dropout),\n        )\n\n    def forward(self, x):\n        skip_out = self.double_conv(x)\n        down_output = self.maxpool_conv(skip_out)\n        return (down_output, skip_out)\n\n    \n\nclass ScDown(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3, dropout = 0.1):\n        super(Down, self).__init__()\n        self.double_conv = ScDoubleConv(in_channels, out_channels, kernel_size)\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p=dropout),\n        )\n\n    def forward(self, x):\n        skip_out = self.double_conv(x)\n        down_output = self.maxpool_conv(skip_out)\n        return (down_output, skip_out)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size = 2, dropout = 0.1, stride = 2):\n        super().__init__()\n        \n        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride)\n        \n        self.conv = nn.Sequential(\n            nn.Dropout2d(p=dropout),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x1, x2):\n        x = self.up(x1)\n        x = torch.cat([x, x2], dim = 1)\n        return self.conv(x)\n    \n\n\nclass ScUp(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size = 2, dropout = 0.1, stride = 2):\n        super().__init__()\n        \n        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride)\n        \n        self.conv = nn.Sequential(\n            nn.Dropout2d(p=dropout),\n            ScDoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x1, x2):\n        x = self.up(x1)\n        x = torch.cat([x, x2], dim = 1)\n        return self.conv(x)\n    \n\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes, n_filters = 64, bilinear=False):\n        super(UNet, self).__init__()\n        self.n_classes = n_classes\n        self.n_channels = n_channels\n        kernel_size = 3\n        dropout = 0.25\n\n        self.down1 = Down(n_channels, n_filters, kernel_size, dropout)\n        self.down2 = Down(n_filters, n_filters * 2, kernel_size, dropout)\n        self.down3 = Down(n_filters * 2, n_filters * 4, kernel_size, dropout)\n        self.down4 = Down(n_filters * 4, n_filters * 8, kernel_size, dropout)\n        \n        self.bottle_conv = DoubleConv(n_filters * 8, n_filters * 16, kernel_size)\n        \n        kernel_size = kernel_size - 1\n        self.up4 = Up(n_filters * 16, n_filters * 8, kernel_size, dropout)\n        self.up3 = Up(n_filters * 8, n_filters * 4, kernel_size, dropout)\n        self.up2 = Up(n_filters * 4, n_filters * 2, kernel_size, dropout)\n        self.up1 = Up(n_filters * 2, n_filters, kernel_size, dropout)\n        \n        self.outc = nn.Conv2d(n_filters, n_classes, kernel_size=1)\n        \n\n    def forward(self, x):\n        \n        x, skip1 = self.down1(x)\n        x, skip2 = self.down2(x)\n        x, skip3 = self.down3(x)\n        x, skip4 = self.down4(x)\n        \n        x = self.bottle_conv(x)\n        \n        x = self.up4(x, skip4)\n        x = self.up3(x, skip3)\n        x = self.up2(x, skip2)\n        x = self.up1(x, skip1)\n        \n        logits = self.outc(x)\n        return logits\n\n    def use_checkpointing(self):\n        self.down1 = torch.utils.checkpoint(self.down1)\n        self.down2 = torch.utils.checkpoint(self.down2)\n        self.down3 = torch.utils.checkpoint(self.down3)\n        self.down4 = torch.utils.checkpoint(self.down4)\n        self.bottle_conv = torch.utils.checkpoint(self.bottle_conv)\n        self.up1 = torch.utils.checkpoint(self.up1)\n        self.up2 = torch.utils.checkpoint(self.up2)\n        self.up3 = torch.utils.checkpoint(self.up3)\n        self.up4 = torch.utils.checkpoint(self.up4)\n        self.outc = torch.utils.checkpoint(self.outc)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.804654Z","iopub.execute_input":"2023-12-20T16:40:00.804933Z","iopub.status.idle":"2023-12-20T16:40:00.839588Z","shell.execute_reply.started":"2023-12-20T16:40:00.804906Z","shell.execute_reply":"2023-12-20T16:40:00.838532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 定义数据集加载器","metadata":{}},{"cell_type":"code","source":"# TODO: image和mask名称不一样时跳过\nclass APODataSet(Dataset):\n    # 格式不对的异常数据\n    invalid_img = [10, 184, 185]\n    def __init__(self, img_dir, mask_dir: str, size) -> None:\n        # 获取所有图片路径\n        self.img_paths = list(Path(img_dir).glob(\"*\"))\n        self.mask_paths = list(Path(mask_dir).glob(\"*\"))\n        for idx in self.invalid_img:\n            del self.img_paths[idx]\n            del self.mask_paths[idx]\n        \n        \n        # 设置 transforms\n        self.transform = transforms.Compose([transforms.Resize(size), transforms.ToTensor()])\n#         self.transform = transforms.Compose([transforms.PILToTensor()])\n\n    # 使用函数加载原始图像\n    def load_orig_image(self, index: int) -> Image.Image:\n        \"Opens an image via a path and returns it.\"\n        image_path = self.img_paths[index]\n        return Image.open(image_path) \n    \n    # 使用函数加载tmask图像\n    def load_mask_image(self, index: int) -> Image.Image:\n        \"Opens an image via a path and returns it.\"\n        image_path = self.mask_paths[index]\n        return Image.open(image_path) \n\n    #  重写 __len__() 方法 (optional but recommended for subclasses of torch.utils.data.Dataset)\n    def __len__(self) -> int:\n        \"Returns the total number of samples.\"\n        return len(self.img_paths)\n\n    # 重写 __getitem__() 方法 (required for subclasses of torch.utils.data.Dataset)\n    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"Returns one sample of data, image and mask (X, y).\"\n        orig_img = self.load_orig_image(index)\n        mask_img = self.load_mask_image(index)\n        \n        orig_img = self.transform(orig_img)\n        mask_img = self.transform(mask_img)\n#         mask_img = mask_img[0]\n#         if orig_img.size()[0] != 3:\n#             print(\"{}: orig_img size: {}\".format(index,orig_img.size()))\n#             return None\n        # return data, mask (X, y)\n        return orig_img, mask_img\n","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.841242Z","iopub.execute_input":"2023-12-20T16:40:00.841989Z","iopub.status.idle":"2023-12-20T16:40:00.854402Z","shell.execute_reply.started":"2023-12-20T16:40:00.841949Z","shell.execute_reply":"2023-12-20T16:40:00.853337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载数据集","metadata":{}},{"cell_type":"code","source":"dataset =  APODataSet(img_dir = \"/kaggle/input/dltrack/apo_images\",\n                      mask_dir = \"/kaggle/input/dltrack/apo_masks\",\n                     size = [512, 512])\n\ntotal = len(dataset)\ntrain_size = int(0.8*total)\nvalidate_size = total - train_size\ntrain_data, validate_data = random_split(dataset, [train_size, validate_size])\nprint(\"dataset info\\ntotal: {}, train_size: {}, validate_size: {}\".format(total, len(train_data), len(validate_data)))\n\ntrainloader = DataLoader(dataset=train_data,\n                                     batch_size=2,\n                                     num_workers=0,\n                                     shuffle=True)\n\nvalloader = DataLoader(dataset=validate_data,\n                                    batch_size=1, \n                                    num_workers=0, \n                                    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.855829Z","iopub.execute_input":"2023-12-20T16:40:00.856277Z","iopub.status.idle":"2023-12-20T16:40:00.877150Z","shell.execute_reply.started":"2023-12-20T16:40:00.856234Z","shell.execute_reply":"2023-12-20T16:40:00.876157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 检查异常图片\n要把找到的异常数据去除","metadata":{}},{"cell_type":"code","source":"for index in range(len(dataset)):\n    orig_img, mask_img = dataset[index]\n    if orig_img.size()[0] != 3:\n        print(\"{}: orig_img size: {}\".format(index,orig_img.size()))\nprint(\"[done]\")","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:00.878352Z","iopub.execute_input":"2023-12-20T16:40:00.878652Z","iopub.status.idle":"2023-12-20T16:40:07.983176Z","shell.execute_reply.started":"2023-12-20T16:40:00.878625Z","shell.execute_reply":"2023-12-20T16:40:07.982360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 随机显示一张原始图片和其对应的标记图片","metadata":{}},{"cell_type":"code","source":"idx = random.randint(0, len(dataset))\norig_img, mask_img = dataset[idx]\nprint(orig_img.size())\n\ntransform = transforms.ToPILImage()\nprint(\"showing image of {}: \".format(idx))\n\norig_img = transform(orig_img)\nmask_img = transform(mask_img)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 12))\n\nax1.imshow(orig_img)\nax1.set_title(\"origin_img\")\n\nax2.imshow(mask_img)\nax2.set_title(\"mask_img\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:07.986594Z","iopub.execute_input":"2023-12-20T16:40:07.988327Z","iopub.status.idle":"2023-12-20T16:40:08.644128Z","shell.execute_reply.started":"2023-12-20T16:40:07.988296Z","shell.execute_reply":"2023-12-20T16:40:08.643011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练网络","metadata":{}},{"cell_type":"code","source":"\n@torch.inference_mode()\ndef evaluate(net, dataloader, device, amp):\n    net.eval()\n    num_val_batches = len(dataloader)\n    dice_score = 0\n    iou_score = 0\n\n    if isinstance(model, nn.DataParallel):\n        n_classes = net.module.n_classes\n    else:\n        n_classes = net.n_classes\n    criterion = nn.CrossEntropyLoss() if n_classes > 1 else nn.BCEWithLogitsLoss()\n    dice_loss = smp.losses.DiceLoss(mode='binary', log_loss=True, from_logits = True).cuda()\n   \n    \n    print(\"Validation round\")\n    # iterate over the validation set\n    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n        for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', position=0 ,leave=True):\n            image, mask_true = batch\n\n            # move images and labels to correct device and type\n            image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n            mask_true = mask_true.to(device=device, dtype=torch.float32)\n\n            # predict the mask\n            mask_pred = net(image)\n            dice_score += criterion(mask_pred, mask_true.float())\n            dice_score += dice_loss(mask_pred, mask_true)\n            \n            tp, fp, fn, tn = smp.metrics.get_stats(mask_pred, mask_true.long(), mode='binary', threshold=0.5)\n            iou_score += smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n            \n    dice_loss = (dice_score / max(num_val_batches, 1))\n    iou_score = (iou_score / max(num_val_batches, 1))\n    print(\"Validation dice loss: {}, IoU Score {}\".format(dice_loss, iou_score))\n    return (dice_loss, iou_score)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:08.646703Z","iopub.execute_input":"2023-12-20T16:40:08.646998Z","iopub.status.idle":"2023-12-20T16:40:08.658764Z","shell.execute_reply.started":"2023-12-20T16:40:08.646970Z","shell.execute_reply":"2023-12-20T16:40:08.657747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 设置wandb账号\n用作统计与数据分析","metadata":{}},{"cell_type":"code","source":"os.environ['WANDB_API_KEY']='d561f1229ba7c4e207ca34042f29a43552a7447e'\n!wandb login","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:08.659932Z","iopub.execute_input":"2023-12-20T16:40:08.660244Z","iopub.status.idle":"2023-12-20T16:40:11.394352Z","shell.execute_reply.started":"2023-12-20T16:40:08.660217Z","shell.execute_reply":"2023-12-20T16:40:11.393086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport torch.optim as optim\nimport segmentation_models_pytorch as smp\n\nn_train = len(train_data)\nn_val = len(validate_data)\n\n\ndef train(model, device, \n          epochs: int = 60,\n          learning_rate: float = 1e-5, \n          weight_decay: float = 1e-8,\n          momentum: float = 0.999,\n          batch_size: int = 2,\n          amp: bool = False,\n          val_percent: float = 0.1,\n          gradient_clipping: float = 1.0,\n          project='ScUNet'):\n    if isinstance(model, nn.DataParallel):\n        n_classes = model.module.n_classes\n        n_channels = model.module.n_channels\n    else:\n        n_classes = model.n_classes\n        n_channels = model.n_channels\n        \n    # (Initialize logging)\n    experiment = wandb.init(project=project, resume='allow', anonymous='must')\n    experiment.config.update(\n        dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n             val_percent=val_percent, amp=amp)\n    )\n\n    logging.info(f'''Starting training:\n        Epochs:          {epochs}\n        Batch size:      {batch_size}\n        Learning rate:   {learning_rate}\n        Training size:   {n_train}\n        Validation size: {n_val}\n        Device:          {device.type}\n        Mixed Precision: {amp}\n    ''')\n    \n     # Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n#     optimizer = optim.RMSprop(model.parameters(),\n#                               lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=5e-5)  # goal: maximize Dice score\n    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n    criterion = nn.CrossEntropyLoss().cuda()\n    dice_loss = smp.losses.DiceLoss(mode='binary')\n    \n    global_step = 0\n    \n#     iou_metric = IoU\n\n    # 5. Begin training\n    for epoch in range(1, epochs + 1):\n        model.train()\n        epoch_loss = 0\n        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n            for batch in trainloader:\n                images, true_masks = batch\n\n                assert images.shape[1] == n_channels, \\\n                    f'Network has been defined with {n_channels} input channels, ' \\\n                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n                    'the images are loaded correctly.'\n\n                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n                \n                true_masks = true_masks.to(device=device, dtype=torch.long)\n\n                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n                    masks_pred = model(images)\n                    loss = criterion(masks_pred, true_masks.float())\n                    loss += dice_loss(masks_pred, true_masks)\n                    tp, fp, fn, tn = smp.metrics.get_stats(masks_pred, true_masks.long(), mode='binary', threshold=0.5)\n                    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n    \n                optimizer.zero_grad(set_to_none=True)\n                grad_scaler.scale(loss).backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n                grad_scaler.step(optimizer)\n                grad_scaler.update()\n\n                pbar.update(images.shape[0])\n                global_step += 1\n                epoch_loss += loss.item()\n                experiment.log({\n                    'train iou': iou_score,\n                    'train loss': loss.item(),\n                    'step': global_step,\n                    'epoch': epoch\n                })\n                pbar.set_postfix(**{'loss (batch)': loss.item()})\n\n                # Evaluation round\n                division_step = (n_train // (5 * batch_size))\n                if division_step > 0:\n                    if global_step % division_step == 0:\n                        histograms = {}\n                        for tag, value in model.named_parameters():\n                            tag = tag.replace('/', '.')\n                            if not (torch.isinf(value) | torch.isnan(value)).any():\n                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n\n                        val_score, iou_score = evaluate(model, valloader, device, amp)\n                        model.train()\n                        scheduler.step(val_score)\n\n                        logging.info('Validation Dice score: {}'.format(val_score))\n                        try:\n                            experiment.log({\n                                'learning rate': optimizer.param_groups[0]['lr'],\n                                'validation Dice': val_score,\n                                'validation IoU Score': iou_score,\n                                'images': wandb.Image(images[0].cpu()),\n                                'masks': {\n                                    'true': wandb.Image(true_masks[0].float().cpu()),\n                                    'pred': wandb.Image(masks_pred[0].float().cpu()),\n                                },\n                                'step': global_step,\n                                'epoch': epoch,\n                                **histograms\n                            })\n                        except:\n                            pass\n            \n\nif __name__ == '__main__':\n    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    if torch.cuda.device_count() > 1:\n        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n        model = nn.DataParallel(model)\n\n    model = model.to(memory_format=torch.channels_last)\n    model.to(device)\n    \n    \n\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"UNet-ScConv模型参数量为：{total_params}\")\n    print(\"其详情为：\")\n    for name,parameters in model.named_parameters():\n        print(name,':',parameters.size())\n\n    train(model, device, project='ScUNet')\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-20T16:40:11.398200Z","iopub.execute_input":"2023-12-20T16:40:11.398528Z","iopub.status.idle":"2023-12-20T16:40:55.873469Z","shell.execute_reply.started":"2023-12-20T16:40:11.398493Z","shell.execute_reply":"2023-12-20T16:40:55.871806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 推理","metadata":{}}]}
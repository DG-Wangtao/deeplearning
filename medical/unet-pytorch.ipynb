{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6361775,"sourceType":"datasetVersion","datasetId":3664633}],"dockerImageVersionId":30528,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 安装依赖","metadata":{}},{"cell_type":"markdown","source":"- https://github.com/milesial/Pytorch-UNet/tree/master\n- https://github.com/njcronin/DL_Track\n- https://github.com/njcronin/DL_Track/blob/master/Labelling_Instructions.pdf","metadata":{}},{"cell_type":"code","source":"!pip install scipy scikit-image torch torchvision pathlib wandb segmentation-models-pytorch\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:03.851612Z","iopub.execute_input":"2024-02-18T15:43:03.852490Z","iopub.status.idle":"2024-02-18T15:43:27.596673Z","shell.execute_reply.started":"2024-02-18T15:43:03.852439Z","shell.execute_reply":"2024-02-18T15:43:27.595937Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.1)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (0.21.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1+cpu)\nCollecting pathlib\n  Downloading pathlib-1.0.1-py3-none-any.whl (14 kB)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\nCollecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2.31.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (1.4.1)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (21.3)\nRequirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image) (0.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: timm==0.9.2 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.65.0)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.16.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.3.1)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.6.0)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=a7b9d3ca6ba7114b774714cbf5cf113d7497d170df6b16a94ada7cf4a03f8a0d\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=de3bf58c20d0f747ab54754bdd708d87d1275668dbe6735cd50b74a37b5e4f39\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: pathlib, munch, efficientnet-pytorch, pretrainedmodels, segmentation-models-pytorch\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pathlib-1.0.1 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.5)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.27.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 引用依赖包","metadata":{}},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:27.598115Z","iopub.execute_input":"2024-02-18T15:43:27.598392Z","iopub.status.idle":"2024-02-18T15:43:27.608504Z","shell.execute_reply.started":"2024-02-18T15:43:27.598367Z","shell.execute_reply":"2024-02-18T15:43:27.607424Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom torchvision.transforms import v2\nfrom torch.nn.functional import relu, pad\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom PIL import Image\nfrom typing import Tuple\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn, Tensor\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom tqdm import tqdm\nimport wandb\nimport logging","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:27.609681Z","iopub.execute_input":"2024-02-18T15:43:27.609997Z","iopub.status.idle":"2024-02-18T15:43:31.408929Z","shell.execute_reply.started":"2024-02-18T15:43:27.609961Z","shell.execute_reply":"2024-02-18T15:43:31.407805Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\n/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n  warnings.warn(_BETA_TRANSFORMS_WARNING)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## U-Net 网络","metadata":{}},{"cell_type":"code","source":"\nclass DoubleConv(nn.Module):\n    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3):\n        super(DoubleConv,self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\n\nclass Down(nn.Module):\n    \"\"\"Downscaling with maxpool then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size=3, dropout = 0.1):\n        super(Down, self).__init__()\n        self.double_conv = DoubleConv(in_channels, out_channels, kernel_size)\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            nn.Dropout2d(p=dropout),\n        )\n\n    def forward(self, x):\n        skip_out = self.double_conv(x)\n        down_output = self.maxpool_conv(skip_out)\n        return (down_output, skip_out)\n\n\nclass Up(nn.Module):\n    \"\"\"Upscaling then double conv\"\"\"\n\n    def __init__(self, in_channels, out_channels, kernel_size = 2, dropout = 0.1, stride = 2):\n        super().__init__()\n        \n        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride)\n        \n        self.conv = nn.Sequential(\n            nn.Dropout2d(p=dropout),\n            DoubleConv(in_channels, out_channels)\n        )\n\n    def forward(self, x1, x2):\n        x = self.up(x1)\n        x = torch.cat([x, x2], dim = 1)\n        return self.conv(x)\n    \n\nsigmoid = nn.Sigmoid()\nif torch.cuda.is_available():\n    sigmoid = sigmoid.cuda()\n\nclass UNet(nn.Module):\n    def __init__(self, input_channels, num_classes, n_filters = 64, bilinear=False):\n        super(UNet, self).__init__()\n        self.num_classes = num_classes\n        self.input_channels = input_channels\n        kernel_size = 3\n        dropout = 0.25\n\n        self.down1 = Down(input_channels, n_filters, kernel_size, dropout)\n        self.down2 = Down(n_filters, n_filters * 2, kernel_size, dropout)\n        self.down3 = Down(n_filters * 2, n_filters * 4, kernel_size, dropout)\n        self.down4 = Down(n_filters * 4, n_filters * 8, kernel_size, dropout)\n        \n        self.bottle_conv = DoubleConv(n_filters * 8, n_filters * 16, kernel_size)\n        \n        kernel_size = kernel_size - 1\n        self.up4 = Up(n_filters * 16, n_filters * 8, kernel_size, dropout)\n        self.up3 = Up(n_filters * 8, n_filters * 4, kernel_size, dropout)\n        self.up2 = Up(n_filters * 4, n_filters * 2, kernel_size, dropout)\n        self.up1 = Up(n_filters * 2, n_filters, kernel_size, dropout)\n        \n        self.outc = nn.Conv2d(n_filters, num_classes, kernel_size=1)\n        \n\n    def forward(self, x):\n        \n        x, skip1 = self.down1(x)\n        x, skip2 = self.down2(x)\n        x, skip3 = self.down3(x)\n        x, skip4 = self.down4(x)\n        \n        x = self.bottle_conv(x)\n        \n        x = self.up4(x, skip4)\n        x = self.up3(x, skip3)\n        x = self.up2(x, skip2)\n        x = self.up1(x, skip1)\n        \n        out = self.outc(x)\n        if not self.training:\n            out = sigmoid(out)\n            out = torch.where(out>0.5,torch.ones_like(out),torch.zeros_like(out))\n        return out\n\n    def use_checkpointing(self):\n        self.down1 = torch.utils.checkpoint(self.down1)\n        self.down2 = torch.utils.checkpoint(self.down2)\n        self.down3 = torch.utils.checkpoint(self.down3)\n        self.down4 = torch.utils.checkpoint(self.down4)\n        self.bottle_conv = torch.utils.checkpoint(self.bottle_conv)\n        self.up1 = torch.utils.checkpoint(self.up1)\n        self.up2 = torch.utils.checkpoint(self.up2)\n        self.up3 = torch.utils.checkpoint(self.up3)\n        self.up4 = torch.utils.checkpoint(self.up4)\n        self.outc = torch.utils.checkpoint(self.outc)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.410153Z","iopub.execute_input":"2024-02-18T15:43:31.410418Z","iopub.status.idle":"2024-02-18T15:43:31.432129Z","shell.execute_reply.started":"2024-02-18T15:43:31.410394Z","shell.execute_reply":"2024-02-18T15:43:31.430517Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 定义数据集加载器","metadata":{}},{"cell_type":"code","source":"# TODO: image和mask名称不一样时跳过\nclass APODataSet(Dataset):\n    # 格式不对的异常数据\n    invalid_img = [10, 184, 185]\n    def __init__(self, img_dir, mask_dir: str, size) -> None:\n        # 获取所有图片路径\n        img_paths = list(Path(img_dir).glob(\"*\"))\n        mask_paths = list(Path(mask_dir).glob(\"*\"))\n        self.images = []\n        self.masks = []\n        for img_idx in range(len(img_paths)):\n            img_path = img_paths[img_idx]\n            img = self.load_image(img_path)\n            num_channels = len(img.getbands())\n            if num_channels != 3:\n                continue\n            \n            mask_path = mask_paths[img_idx]\n#             mask = self.load_image(mask_path)\n            self.images.append(img_path)\n            self.masks.append(mask_path)\n            \n        # 设置 transforms\n        self.transform = v2.Compose([     v2.Resize(size), \n                                             v2.RandomHorizontalFlip(),  # 随机水平翻转\n                                             v2.RandomVerticalFlip(),    # 随机垂直旋转\n                                             v2.RandomRotation(10) ,     # 随机旋转 （-10,10）度\n                                             v2.ToImageTensor(), v2.ConvertImageDtype()])\n#         self.transform = transforms.Compose([transforms.PILToTensor()])\n\n    def load_image(self, path) -> Image.Image:\n        \"Opens an image via a path and returns it.\"\n        return Image.open(path)\n    \n    #  重写 __len__() 方法 (optional but recommended for subclasses of torch.utils.data.Dataset)\n    def __len__(self) -> int:\n        \"Returns the total number of samples.\"\n        return len(self.images)\n\n    # 重写 __getitem__() 方法 (required for subclasses of torch.utils.data.Dataset)\n    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"Returns one sample of data, image and mask (X, y).\"\n        orig_img = self.load_image(self.images[index])\n        mask_img = self.load_image(self.masks[index])\n        \n        seed = np.random.randint(2147483647)\n        torch.manual_seed(seed)   # 指定同样的随机种子，以保证图片和label的旋转（水平、垂直和rotation）一致\n        orig_img = self.transform(orig_img)\n        torch.manual_seed(seed)  # 指定同样的随机种子，以保证图片和label的旋转（水平、垂直和rotation）一致\n        mask_img = self.transform(mask_img)\n        \n        mask_img = torch.where(mask_img>0.5,torch.ones_like(mask_img),torch.zeros_like(mask_img))\n        return orig_img, mask_img\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.434884Z","iopub.execute_input":"2024-02-18T15:43:31.435135Z","iopub.status.idle":"2024-02-18T15:43:31.447699Z","shell.execute_reply.started":"2024-02-18T15:43:31.435114Z","shell.execute_reply":"2024-02-18T15:43:31.446306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## 定义训练和验证的方法","metadata":{}},{"cell_type":"code","source":"\n@torch.inference_mode()\ndef evaluate(net, dataloader, device, amp, experiment):\n    net.eval()\n    num_val_batches = len(dataloader)\n    \n    bce_loss = 0\n    dice_loss = 0\n    iou_score = 0\n\n    if isinstance(model, nn.DataParallel):\n        num_classes = net.module.num_classes\n    else:\n        num_classes = net.num_classes\n    \n    # 因为在非训练过程（推理过程中），已经在网络最后一层加了log和过滤\n    # 因此这里的损失函数都要使用不带log的\n    criterion = nn.BCELoss()\n    diceloss = smp.losses.DiceLoss(mode='binary', from_logits=False)\n    \n    if torch.cuda.is_available():\n        criterion = criterion.cuda()\n        diceloss = diceloss.cuda()\n        \n    \n    # iterate over the validation set\n    with tqdm(total=num_val_batches, desc='Validation round', unit='batch', position=0 ,leave=True) as pbar:\n        for batch in dataloader:\n\n            images, mask_true = batch\n\n            # move images and labels to correct device and type\n            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n            mask_true = mask_true.to(device=device, dtype=torch.float32)\n\n            # predict the mask\n            mask_pred = net(images)\n            bce_loss += criterion(mask_pred, mask_true.float())\n            dice_loss += diceloss(mask_pred, mask_true)\n\n            tp, fp, fn, tn = smp.metrics.get_stats(mask_pred, mask_true.long(), mode='binary', threshold=0.5)\n            iou_score += smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n            pbar.update(images.shape[0])\n\n        bce_loss = (bce_loss / max(num_val_batches, 1))\n        dice_loss = (dice_loss / max(num_val_batches, 1))\n\n        iou_score = (iou_score / max(num_val_batches, 1))\n        pbar.set_postfix(**{\"Validation bce loss\": bce_loss.item(), \"dice loss\": dice_loss.item(), \"IoU Score\": iou_score.item()})\n    \n    try:\n        histograms = {}\n        for tag, value in net.named_parameters():\n            tag = tag.replace('/', '.')\n            if not (value is None) and not (torch.isinf(value) | torch.isnan(value)).any():\n                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n            if not (value.grad is None) and not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n\n        experiment.log({\n            'validation Loss': bce_loss + dice_loss,\n            'validation IoU Score': iou_score,\n            'images': wandb.Image(images[0].cpu()),\n            'masks': {\n                'true': wandb.Image(mask_true[0].float().cpu()),\n                'pred': wandb.Image(mask_pred[0].float().cpu()),\n            },\n            **histograms\n        })\n    except Exception as e:\n        print(e)\n        pass\n    \n    return (dice_loss, iou_score)    \n     \n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.449512Z","iopub.execute_input":"2024-02-18T15:43:31.449890Z","iopub.status.idle":"2024-02-18T15:43:31.467772Z","shell.execute_reply.started":"2024-02-18T15:43:31.449852Z","shell.execute_reply":"2024-02-18T15:43:31.466052Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[6], line 54\u001b[0;36m\u001b[0m\n\u001b[0;31m    if not (torch.isinf(value) || torch.isnan(value)):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (4130403133.py, line 54)","output_type":"error"}]},{"cell_type":"code","source":"import time\nimport torch.optim as optim\nimport segmentation_models_pytorch as smp\n\ndef train(model, device, project,\n          epochs: int = 60,\n          learning_rate: float = 1e-5, \n          weight_decay: float = 1e-8,\n          momentum: float = 0.999,\n          batch_size: int = 6,\n          amp: bool = False,\n          gradient_clipping: float = 1.0):\n    n_train = len(train_data)\n    n_val = len(validate_data)\n\n\n    if isinstance(model, nn.DataParallel):\n        num_classes = model.module.num_classes\n        input_channels = model.module.input_channels\n    else:\n        num_classes = model.num_classes\n        input_channels = model.input_channels\n        \n\n    # (Initialize logging)\n    experiment = wandb.init(project=project, resume='allow', anonymous='must', notes='水平和垂直翻转，旋转(-10,10)度')\n    experiment.config.update(\n        dict(epochs=epochs, batch_size=batch_size, amp=True)\n    )\n    logging.info(f'''Starting training:\n        Epochs:          {epochs}\n        Batch size:      {batch_size}\n        Learning rate:   {learning_rate}\n        Training size:   {n_train}\n        Validation size: {n_val}\n        Device:          {device.type}\n        Mixed Precision: {amp}\n    ''')\n    \n\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2, eta_min=5e-5)  # goal: maximize Dice scor\n    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n    \n    # 训练过程中，网络最后一层没有添加log，所以要使用带log的损失函数\n    criterion = nn.BCEWithLogitsLoss().cuda()\n    dice_loss = smp.losses.DiceLoss(mode='binary', from_logits=True).cuda()\n\n    global_step = 0\n\n    # 5. Begin training\n    for epoch in range(1, epochs + 1):\n        model.train()\n        epoch_loss = 0\n        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='batch') as pbar:\n            for batch in trainloader:\n                images, true_masks = batch\n\n                assert images.shape[1] == input_channels, \\\n                    f'Network has been defined with {input_channels} input channels, ' \\\n                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n                    'the images are loaded correctly.'\n\n                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n                \n                true_masks = true_masks.to(device=device, dtype=torch.long)\n\n                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n                    masks_pred = model(images)\n                    loss = criterion(masks_pred, true_masks.float())\n                    loss += dice_loss(masks_pred, true_masks)\n                    tp, fp, fn, tn = smp.metrics.get_stats(masks_pred, true_masks.long(), mode='binary', threshold=0.5)\n                    iou_score = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n    \n                optimizer.zero_grad(set_to_none=True)\n                grad_scaler.scale(loss).backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n                grad_scaler.step(optimizer)\n                grad_scaler.update()\n\n                pbar.update(images.shape[0])\n                global_step += 1\n                epoch_loss += loss.item()\n                pbar.set_postfix(**{'loss (batch)': epoch_loss/n_train})\n                if global_step % 10 == 0:\n                    experiment.log({\n                        'learning rate': optimizer.param_groups[0]['lr'],\n                        'train iou': iou_score,\n                        'train loss': loss.item(),\n                        'step': global_step,\n                        'epoch': epoch\n                    })\n                \n\n           # Evaluation round\n                division_step = (n_train // batch_size)\n                if division_step > 0:\n                    if global_step % division_step == 0:\n                        val_score, iou_score = evaluate(model, valloader, device, amp, experiment)\n                        \n                        model.train()\n                        scheduler.step(val_score)\n    experiment.finish()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.468806Z","iopub.status.idle":"2024-02-18T15:43:31.469639Z","shell.execute_reply.started":"2024-02-18T15:43:31.469271Z","shell.execute_reply":"2024-02-18T15:43:31.469313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 加载数据集","metadata":{}},{"cell_type":"code","source":"batch_size=8\n\ndataset =  APODataSet(img_dir = \"/kaggle/input/dltrack/apo_images\",\n                      mask_dir = \"/kaggle/input/dltrack/apo_masks\",\n                     size = [512, 512])\n\ntotal = len(dataset)\ntrain_size = int(0.8*total)\nvalidate_size = total - train_size\ntrain_data, validate_data = random_split(dataset, [train_size, validate_size])\nprint(\"dataset info\\ntotal: {}, train_size: {}, validate_size: {}\".format(total, len(train_data), len(validate_data)))\n\ntrainloader = DataLoader(dataset=train_data,\n                                     batch_size=batch_size,\n                                     num_workers=0,\n                                     shuffle=True)\n\nvalloader = DataLoader(dataset=validate_data,\n                                    batch_size=1, \n                                    num_workers=0, \n                                    shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.471757Z","iopub.status.idle":"2024-02-18T15:43:31.472748Z","shell.execute_reply.started":"2024-02-18T15:43:31.472453Z","shell.execute_reply":"2024-02-18T15:43:31.472501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 检查异常图片\n要把找到的异常数据去除","metadata":{}},{"cell_type":"code","source":"for index in range(len(dataset)):\n    orig_img, mask_img = dataset[index]\n    if orig_img.size()[0] != 3:\n        print(\"{}: orig_img size: {}\".format(index,orig_img.size()))\nprint(\"[done]\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.474234Z","iopub.status.idle":"2024-02-18T15:43:31.474727Z","shell.execute_reply.started":"2024-02-18T15:43:31.474442Z","shell.execute_reply":"2024-02-18T15:43:31.474483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 随机显示一张原始图片和其对应的标记图片","metadata":{}},{"cell_type":"code","source":"idx = random.randint(0, len(dataset))\norig_img, mask_img = dataset[idx]\n\nprint(orig_img.size())\nprint(mask_img.size())\n\n\nprint(\"showing image of {}: \".format(idx))\n\norig_img = orig_img.cpu().numpy().transpose(1, 2, 0)\nmask_img = mask_img.cpu().numpy().transpose(1, 2, 0)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 12))\n\nax1.imshow(orig_img)\nax1.grid(False)\nax1.axis('off')\nax1.set_title(\"origin_img\")\n\nax2.imshow(mask_img, cmap=\"gray\")\nax2.grid(False)\nax2.axis('off')\nax2.set_title(\"mask_img\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.476208Z","iopub.status.idle":"2024-02-18T15:43:31.476676Z","shell.execute_reply.started":"2024-02-18T15:43:31.476428Z","shell.execute_reply":"2024-02-18T15:43:31.476449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 训练网络","metadata":{}},{"cell_type":"code","source":"os.environ['WANDB_API_KEY']='d561f1229ba7c4e207ca34042f29a43552a7447e'\n!wandb login\n\n\n# (Initialize logging)\nexperiment = wandb.init(project='U-Net', resume='allow', anonymous='must', notes='水平和垂直翻转，旋转(-10,10)度')\nexperiment.config.update(\n    dict(epochs=200, batch_size=batch_size, amp=True)\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.478300Z","iopub.status.idle":"2024-02-18T15:43:31.478755Z","shell.execute_reply.started":"2024-02-18T15:43:31.478535Z","shell.execute_reply":"2024-02-18T15:43:31.478554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 设置wandb账号\n用作统计与数据分析","metadata":{}},{"cell_type":"code","source":"epochs=100\nif __name__ == '__main__':\n    model = UNet(input_channels=3, num_classes=1, bilinear=False)\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    if torch.cuda.device_count() > 1:\n        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n        model = nn.DataParallel(model)\n\n    model = model.to(memory_format=torch.channels_last)\n    model.to(device)\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"模型参数量为：{total_params}\")\n    print(\"其详情为：\")\n    for name,parameters in model.named_parameters():\n        print(name,':',parameters.size())\n    train(model, device, project=\"U-Net\", epochs=epochs, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T15:43:31.479780Z","iopub.status.idle":"2024-02-18T15:43:31.480173Z","shell.execute_reply.started":"2024-02-18T15:43:31.479974Z","shell.execute_reply":"2024-02-18T15:43:31.479993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 推理","metadata":{}}]}